name: mlp-hyperparam-sweep
method: grid
project: Elodea MLP
metric:
  name: testing_loss
  goal: minimize

parameters:
  input_size:
    values: [224]
  hidden_sizes:
    values: [32, 64, 128, 256, 512]
  hidden_depth:
    values: [3, 4]
  learning_rate:
    values: [0.0001, 0.00001, 0.000001]
  activation_function:
    values: [relu, leaky_relu]
  optimizer:
    values: [sgd, adam]
  epochs:
    values: [40, 60]
  batch_size:
    values: [32]